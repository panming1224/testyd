"""
äº¬ä¸œåº—é“ºåº“å­˜æ•°æ®è‡ªåŠ¨æ‹‰å–è„šæœ¬ - æ•™å­¦ç‰ˆ
=================================

è¿™ä¸ªè„šæœ¬çš„ä¸»è¦åŠŸèƒ½ï¼š
1. è‡ªåŠ¨ç™»å½•äº¬ä¸œå•†å®¶åå°
2. è·å–åº—é“ºåº“å­˜æŠ¥è¡¨æ•°æ®
3. ä¸‹è½½å¹¶æ•´ç†Excelæ–‡ä»¶
4. åˆå¹¶å¤šä¸ªåº—é“ºçš„æ•°æ®
5. ä¸Šä¼ åˆ°MinIOæ•°æ®ä»“åº“

ä½œè€…ï¼šAIåŠ©æ‰‹
æ—¥æœŸï¼š2025-09-26
ç‰ˆæœ¬ï¼šæ•™å­¦ç‰ˆ v1.0

å­¦ä¹ é‡ç‚¹ï¼š
- PythonåŸºç¡€è¯­æ³•
- æ–‡ä»¶æ“ä½œ
- ç½‘ç»œè¯·æ±‚
- æ•°æ®å¤„ç†
- å¼‚å¸¸å¤„ç†
"""

# ========================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå¯¼å…¥æ¨¡å—ï¼ˆImport Modulesï¼‰
# ========================================

# å¯¼å…¥æ¨¡å—å°±åƒæ˜¯"å€Ÿç”¨å·¥å…·"ï¼Œæ¯ä¸ªæ¨¡å—æä¾›ä¸åŒçš„åŠŸèƒ½

# 1. æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…· - ç”¨æ¥æ§åˆ¶æµè§ˆå™¨
from playwright.sync_api import sync_playwright

# 2. æ—¶é—´ç›¸å…³å·¥å…·
import time           # ç”¨æ¥æš‚åœç¨‹åºæ‰§è¡Œ
from datetime import datetime, timedelta  # ç”¨æ¥å¤„ç†æ—¥æœŸå’Œæ—¶é—´

# 3. æ•°æ®å¤„ç†å·¥å…·
import json          # ç”¨æ¥å¤„ç†JSONæ ¼å¼æ•°æ®
import pandas as pd  # ç”¨æ¥å¤„ç†Excelå’Œæ•°æ®è¡¨æ ¼

# 4. ç½‘ç»œè¯·æ±‚å·¥å…·
import requests      # ç”¨æ¥å‘é€HTTPè¯·æ±‚ï¼ˆä¸‹è½½æ–‡ä»¶ã€è°ƒç”¨APIï¼‰

# 5. æ–‡ä»¶å’Œç³»ç»Ÿæ“ä½œå·¥å…·
import os            # ç”¨æ¥æ“ä½œæ–‡ä»¶å¤¹
import shutil        # ç”¨æ¥ç§»åŠ¨ã€å¤åˆ¶æ–‡ä»¶
from pathlib import Path  # æ›´ç°ä»£çš„æ–‡ä»¶è·¯å¾„å¤„ç†æ–¹å¼

# 6. å…¶ä»–å·¥å…·
import uuid          # ç”¨æ¥ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
import sys           # ç”¨æ¥æ“ä½œPythonç³»ç»Ÿè®¾ç½®

# 7. å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆ ourselveså†™çš„å·¥å…·ï¼‰
sys.path.append(r'D:\testyd')  # å‘Šè¯‰Pythonå»å“ªé‡Œæ‰¾æˆ‘ä»¬çš„æ¨¡å—
from merge_excel_files import ExcelMerger  # å¯¼å…¥Excelåˆå¹¶å·¥å…·

# ========================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šé…ç½®å‚æ•°ï¼ˆConfigurationï¼‰
# ========================================

# é…ç½®å°±åƒæ˜¯"è®¾ç½®"ï¼Œå‘Šè¯‰ç¨‹åºå»å“ªé‡Œæ‰¾æ–‡ä»¶ã€ä¿å­˜åˆ°å“ªé‡Œç­‰

# åº—é“ºä¿¡æ¯Excelæ–‡ä»¶çš„ä½ç½®
EXCEL_PATH = r'D:\yingdao\jd\åº—é“ºä¿¡æ¯è¡¨.xlsx'

# å­˜æ¡£ç›®å½• - ç”¨æ¥ä¿å­˜ä¸‹è½½çš„æ–‡ä»¶
BASE_ARCHIVE_DIR = Path('D:/yingdao/jd/åº“å­˜è¡¨')

# åˆå¹¶æ–‡ä»¶ç›®å½• - ç”¨æ¥ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
MERGED_FILES_DIR = Path('D:/yingdao/jd/åˆå¹¶è¡¨æ ¼')

# Excelè¡¨æ ¼çš„å·¥ä½œè¡¨ç¼–å·ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€ä¸ªå·¥ä½œè¡¨ï¼‰
SHEET = 0

# MinIOæ•°æ®ä»“åº“çš„é…ç½®
MINIO_API_URL = "http://127.0.0.1:8009/api/upload"  # APIåœ°å€
MINIO_BUCKET = "warehouse"  # å­˜å‚¨æ¡¶åç§°

# åˆ›å»ºå¿…è¦çš„æ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨å°±åˆ›å»ºï¼‰
# os.makedirs() å‡½æ•°ç”¨æ³•ï¼š
# - ç¬¬ä¸€ä¸ªå‚æ•°ï¼šè¦åˆ›å»ºçš„æ–‡ä»¶å¤¹è·¯å¾„
# - exist_ok=Trueï¼šå¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œä¸æŠ¥é”™
os.makedirs(BASE_ARCHIVE_DIR, exist_ok=True)
os.makedirs(MERGED_FILES_DIR, exist_ok=True)

# è®¡ç®—æ˜¨å¤©çš„æ—¥æœŸï¼ˆT-1æ—¥æœŸï¼‰
# datetime.now() - è·å–å½“å‰æ—¶é—´
# timedelta(days=1) - è¡¨ç¤º1å¤©çš„æ—¶é—´å·®
# strftime('%Y-%m-%d') - æ ¼å¼åŒ–ä¸º "å¹´-æœˆ-æ—¥" æ ¼å¼
TODAY_STR = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

print(f"ğŸ“… ä»Šå¤©å¤„ç†çš„æ—¥æœŸæ˜¯ï¼š{TODAY_STR}")

# ========================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šå‡½æ•°å®šä¹‰ï¼ˆFunction Definitionsï¼‰
# ========================================

def update_header_once(df: pd.DataFrame):
    """
    æ›´æ–°Excelè¡¨å¤´çš„å‡½æ•°
    
    å‡½æ•°è¯´æ˜ï¼š
    - è¿™ä¸ªå‡½æ•°ç”¨æ¥æ›´æ–°Excelæ–‡ä»¶çš„è¡¨å¤´
    - æŠŠFåˆ—çš„æ ‡é¢˜æ”¹æˆä»Šå¤©çš„æ—¥æœŸ+ä¸‹è½½çŠ¶æ€
    - å¦‚æœä»Šå¤©å·²ç»æ›´æ–°è¿‡äº†ï¼Œå°±ä¸é‡å¤æ›´æ–°
    
    å‚æ•°è¯´æ˜ï¼š
    - df: pandas DataFrameå¯¹è±¡ï¼Œä»£è¡¨Excelè¡¨æ ¼çš„æ•°æ®
    
    è¿”å›å€¼ï¼š
    - True: è¡¨ç¤ºæ›´æ–°äº†è¡¨å¤´
    - False: è¡¨ç¤ºä»Šå¤©å·²ç»æ›´æ–°è¿‡ï¼Œæ²¡æœ‰é‡å¤æ›´æ–°
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    df = pd.read_excel('æ–‡ä»¶.xlsx')
    result = update_header_once(df)
    if result:
        print("è¡¨å¤´å·²æ›´æ–°")
    else:
        print("ä»Šå¤©å·²ç»æ›´æ–°è¿‡äº†")
    """
    
    # ç”Ÿæˆæ–°çš„çŠ¶æ€åˆ—åç§°
    new_status = f'{TODAY_STR}åº“å­˜è¡¨ä¸‹è½½çŠ¶æ€'
    
    # è·å–Fåˆ—ï¼ˆç´¢å¼•ä¸º5ï¼‰çš„å½“å‰åç§°
    # df.columns[5] è¡¨ç¤ºè·å–ç¬¬6åˆ—çš„åˆ—åï¼ˆå› ä¸ºç´¢å¼•ä»0å¼€å§‹ï¼‰
    old_header = df.columns[5]
    
    print(f"ğŸ” æ£€æŸ¥è¡¨å¤´ï¼šå½“å‰Fåˆ—åç§°æ˜¯ '{old_header}'")
    print(f"ğŸ” éœ€è¦çš„Fåˆ—åç§°æ˜¯ '{new_status}'")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ä»Šå¤©çš„æ ¼å¼
    if old_header == new_status:
        print("âœ… ä»Šå¤©å·²ç»æ›´æ–°è¿‡è¡¨å¤´ï¼Œè·³è¿‡æ›´æ–°")
        return False  # è¿”å›Falseè¡¨ç¤ºæ²¡æœ‰æ›´æ–°
    
    # æ›´æ–°åˆ—å
    # df.rename() ç”¨æ¥é‡å‘½ååˆ—
    # columns={æ—§åç§°: æ–°åç§°} æ˜¯é‡å‘½åçš„è§„åˆ™
    # inplace=True è¡¨ç¤ºç›´æ¥ä¿®æ”¹åŸæ•°æ®ï¼Œä¸åˆ›å»ºæ–°çš„å‰¯æœ¬
    df.rename(columns={old_header: new_status}, inplace=True)
    
    # æ¸…ç©ºFåˆ—çš„æ‰€æœ‰æ•°æ®ï¼ˆä¿ç•™è¡¨å¤´ï¼‰
    # df.iloc[:, 5] è¡¨ç¤ºé€‰æ‹©æ‰€æœ‰è¡Œçš„ç¬¬6åˆ—
    # '' è¡¨ç¤ºç©ºå­—ç¬¦ä¸²
    df.iloc[:, 5] = ''
    
    # ç«‹å³ä¿å­˜åˆ°Excelæ–‡ä»¶
    # to_excel() ç”¨æ¥ä¿å­˜DataFrameåˆ°Excelæ–‡ä»¶
    # index=False è¡¨ç¤ºä¸ä¿å­˜è¡Œç´¢å¼•
    # engine='openpyxl' æŒ‡å®šä½¿ç”¨openpyxlå¼•æ“å¤„ç†Excel
    df.to_excel(EXCEL_PATH, index=False, engine='openpyxl')
    
    print(f"âœ… è¡¨å¤´å·²æ›´æ–°ä¸ºï¼š{new_status}")
    return True  # è¿”å›Trueè¡¨ç¤ºå·²æ›´æ–°


def fetch_download_link_and_download(shop_name: str, profile: str):
    """
    è·å–ä¸‹è½½é“¾æ¥å¹¶ä¸‹è½½æ–‡ä»¶çš„ä¸»è¦å‡½æ•°
    
    å‡½æ•°è¯´æ˜ï¼š
    - è¿™æ˜¯æ•´ä¸ªè„šæœ¬çš„æ ¸å¿ƒå‡½æ•°
    - è´Ÿè´£æ‰“å¼€æµè§ˆå™¨ã€ç™»å½•äº¬ä¸œã€è·å–æ•°æ®ã€ä¸‹è½½æ–‡ä»¶
    
    å‚æ•°è¯´æ˜ï¼š
    - shop_name: åº—é“ºåç§°ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰
    - profile: æµè§ˆå™¨é…ç½®æ–‡ä»¶åç§°ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰
    
    è¿”å›å€¼ï¼š
    - True: ä¸‹è½½æˆåŠŸ
    - False: ä¸‹è½½å¤±è´¥
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    success = fetch_download_link_and_download("æµ‹è¯•åº—é“º", "Profile 1")
    if success:
        print("ä¸‹è½½æˆåŠŸ")
    else:
        print("ä¸‹è½½å¤±è´¥")
    """
    
    print(f"\nğŸš€ å¼€å§‹å¤„ç†åº—é“ºï¼š{shop_name}")
    print(f"ğŸ“ ä½¿ç”¨æµè§ˆå™¨é…ç½®ï¼š{profile}")
    
    # æµè§ˆå™¨ç”¨æˆ·æ•°æ®ç›®å½•ï¼ˆå­˜å‚¨ç™»å½•ä¿¡æ¯ã€Cookieç­‰ï¼‰
    USER_DATA_DIR = r"C:\\Users\\1\AppData\\Local\\Chromium\\User Data"
    
    # ç›®æ ‡ç½‘é¡µåœ°å€
    TARGET_URL = "https://ppzh.jd.com/scbrandweb/brand/view/supplyReport/supplyChainPro.html"
    
    # ä½¿ç”¨ try-except æ¥å¤„ç†å¯èƒ½å‡ºç°çš„é”™è¯¯
    try:
        # ========================================
        # æ­¥éª¤1ï¼šå¯åŠ¨æµè§ˆå™¨å¹¶ç™»å½•
        # ========================================
        
        print(f"ğŸŒ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
        
        # sync_playwright() æ˜¯Playwrightçš„å…¥å£
        # ä½¿ç”¨ with è¯­å¥ç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾
        with sync_playwright() as p:
            
            # å¯åŠ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡
            # launch_persistent_context() ç”¨æ¥å¯åŠ¨å¸¦ç”¨æˆ·æ•°æ®çš„æµè§ˆå™¨
            context = p.chromium.launch_persistent_context(
                user_data_dir=USER_DATA_DIR,  # ç”¨æˆ·æ•°æ®ç›®å½•
                headless=False,               # Falseè¡¨ç¤ºæ˜¾ç¤ºæµè§ˆå™¨çª—å£
                args=[                        # æµè§ˆå™¨å¯åŠ¨å‚æ•°
                    "--start-maximized",      # æœ€å¤§åŒ–çª—å£
                    "--no-sandbox",           # ç¦ç”¨æ²™ç›’æ¨¡å¼
                    "--disable-dev-shm-usage",  # ç¦ç”¨/dev/shmä½¿ç”¨
                    "--disable-blink-features=AutomationControlled",  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
                    f"--profile-directory={profile}"  # æŒ‡å®šé…ç½®æ–‡ä»¶
                ],
                no_viewport=True,             # ä¸é™åˆ¶è§†å£å¤§å°
                ignore_https_errors=True      # å¿½ç•¥HTTPSé”™è¯¯
            )
            
            # åˆ›å»ºæ–°é¡µé¢
            page = context.new_page()
            
            print(f"ğŸ”— æ­£åœ¨è®¿é—®äº¬ä¸œé¡µé¢...")
            
            # è®¿é—®ç›®æ ‡ç½‘é¡µ
            # goto() ç”¨æ¥å¯¼èˆªåˆ°æŒ‡å®šURL
            # wait_until="domcontentloaded" ç­‰å¾…é¡µé¢DOMåŠ è½½å®Œæˆ
            # timeout=30000 è®¾ç½®30ç§’è¶…æ—¶
            page.goto(TARGET_URL, wait_until="domcontentloaded", timeout=30000)
            
            # ========================================
            # æ­¥éª¤2ï¼šè·å–Cookieï¼ˆç”¨äºAPIè¯·æ±‚ï¼‰
            # ========================================
            
            print(f"ğŸª æ­£åœ¨è·å–Cookie...")
            
            # è·å–å½“å‰é¡µé¢çš„Cookie
            # cookies() æ–¹æ³•è¿”å›æŒ‡å®šURLçš„æ‰€æœ‰Cookie
            cookies = context.cookies(TARGET_URL)
            
            # å°†Cookieè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼å’Œjoin()æ–¹æ³•
            # f"{c['name']}={c['value']}" æ ¼å¼åŒ–æ¯ä¸ªCookie
            # '; '.join() ç”¨åˆ†å·è¿æ¥æ‰€æœ‰Cookie
            cookie_str = '; '.join(f"{c['name']}={c['value']}" for c in cookies)
            
            print(f"âœ… Cookieè·å–æˆåŠŸï¼Œé•¿åº¦ï¼š{len(cookie_str)}")
            
            # ========================================
            # æ­¥éª¤3ï¼šå‘é€APIè¯·æ±‚ç”ŸæˆæŠ¥è¡¨
            # ========================================
            
            print(f"ğŸ“Š æ­£åœ¨è¯·æ±‚ç”ŸæˆæŠ¥è¡¨...")
            
            # ç”Ÿæˆå”¯ä¸€çš„è¯·æ±‚ID
            # uuid.uuid4() ç”ŸæˆéšæœºUUID
            # str() è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            request_uuid = str(uuid.uuid4())
            
            # æ„å»ºAPIè¯·æ±‚URL
            url = f"https://zhgateway.jd.com/inventoryajax/reportCenter/recommendReport/downloadERPSupplyChainProData.ajax?uuid={request_uuid}"
            
            # è®¾ç½®HTTPè¯·æ±‚å¤´
            # è¯·æ±‚å¤´å‘Šè¯‰æœåŠ¡å™¨æˆ‘ä»¬çš„æµè§ˆå™¨ä¿¡æ¯ã€æ¥å—çš„æ•°æ®ç±»å‹ç­‰
            headers = {
                "accept": "application/json, text/plain, */*",  # æ¥å—çš„æ•°æ®ç±»å‹
                "accept-language": "zh-CN,zh;q=0.9",           # è¯­è¨€åå¥½
                "content-type": "application/json;charset=UTF-8",  # å‘é€çš„æ•°æ®ç±»å‹
                "origin": "https://ppzh.jd.com",               # è¯·æ±‚æ¥æº
                "priority": "u=1, i",                          # è¯·æ±‚ä¼˜å…ˆçº§
                "referer": "https://ppzh.jd.com/scbrandweb/brand/view/supplyReport/supplyChainPro.html",  # å¼•ç”¨é¡µé¢
                "cookie": cookie_str,                          # Cookieä¿¡æ¯
                "sec-ch-ua": "\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"",  # æµè§ˆå™¨ä¿¡æ¯
                "sec-ch-ua-mobile": "?0",                      # æ˜¯å¦ç§»åŠ¨è®¾å¤‡
                "sec-ch-ua-platform": "\"Windows\"",          # æ“ä½œç³»ç»Ÿ
                "sec-fetch-dest": "empty",                     # è¯·æ±‚ç›®æ ‡
                "sec-fetch-mode": "cors",                      # è¯·æ±‚æ¨¡å¼
                "sec-fetch-site": "same-site",                 # è¯·æ±‚ç«™ç‚¹
                "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",  # ç”¨æˆ·ä»£ç†
                "user-mnp": "",                                # ç”¨æˆ·æ ‡è¯†
                "user-mup": "1",                               # ç”¨æˆ·æ ‡è¯†
                "x-requested-with": "XMLHttpRequest"           # AJAXè¯·æ±‚æ ‡è¯†
            }
            
            # è®¾ç½®è¯·æ±‚æ•°æ®
            # è¿™äº›å‚æ•°å‘Šè¯‰äº¬ä¸œæˆ‘ä»¬è¦ä»€ä¹ˆæ ·çš„æŠ¥è¡¨
            data = {
                "isRdc": "0",                    # æ˜¯å¦RDC
                "brandId": "all",                # å“ç‰ŒIDï¼ˆallè¡¨ç¤ºæ‰€æœ‰ï¼‰
                "firstCategoryId": "",           # ä¸€çº§åˆ†ç±»ID
                "secondCategoryId": "",          # äºŒçº§åˆ†ç±»ID
                "thirdCategoryId": "all",        # ä¸‰çº§åˆ†ç±»ID
                "date": TODAY_STR,               # æ—¥æœŸ
                "startDate": TODAY_STR,          # å¼€å§‹æ—¥æœŸ
                "endDate": TODAY_STR,            # ç»“æŸæ—¥æœŸ
                "skuId": "",                     # å•†å“ID
                "skuStatusCd": "",               # å•†å“çŠ¶æ€
                "dataType": "realtime",          # æ•°æ®ç±»å‹ï¼ˆå®æ—¶ï¼‰
                "id": 2,                         # æŠ¥è¡¨ID
                "excludeEmpty": "0"              # æ˜¯å¦æ’é™¤ç©ºæ•°æ®
            }
            
            # å‘é€POSTè¯·æ±‚
            # requests.post() å‘é€POSTè¯·æ±‚
            # json.dumps(data) å°†å­—å…¸è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            response = requests.post(url, headers=headers, data=json.dumps(data))
            
            print(f"ğŸ“¡ APIå“åº”çŠ¶æ€ç ï¼š{response.status_code}")
            print(f"ğŸ“¡ APIå“åº”å†…å®¹ï¼š{response.text[:200]}...")  # åªæ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
            
            # ========================================
            # æ­¥éª¤4ï¼šå¯¼èˆªåˆ°æŠ¥è¡¨é¡µé¢
            # ========================================
            
            print(f"ğŸ“„ æ­£åœ¨å¯¼èˆªåˆ°æŠ¥è¡¨é¡µé¢...")
            
            # è®¿é—®æŠ¥è¡¨åˆ—è¡¨é¡µé¢
            page.goto('https://ppzh.jd.com/brand/reportCenter/myReport.html', 
                     wait_until="domcontentloaded", timeout=30000)
            
            # ========================================
            # æ­¥éª¤5ï¼šç›‘æ§æŠ¥è¡¨çŠ¶æ€å¹¶ä¸‹è½½
            # ========================================
            
            print(f"ğŸ‘€ å¼€å§‹ç›‘æ§æŠ¥è¡¨ç”ŸæˆçŠ¶æ€...")
            
            # ç”Ÿæˆæ–°çš„APIè¯·æ±‚UUID
            api_uuid = str(uuid.uuid4()).replace('-', '') + '-' + str(int(time.time() * 1000))[-11:]
            
            # æ„å»ºçŠ¶æ€æŸ¥è¯¢API URL
            api_url = f"https://ppzh.jd.com/brand/reportCenter/myReport/getReportList.ajax?uuid={api_uuid}"
            
            # è·å–æŠ¥è¡¨é¡µé¢çš„Cookie
            cookie1 = context.cookies('https://ppzh.jd.com/brand/reportCenter/myReport.html')
            cookie_str1 = '; '.join(f"{c['name']}={c['value']}" for c in cookie1)
            
            print(f"ğŸª æŠ¥è¡¨é¡µé¢Cookieè·å–æˆåŠŸ")
            
            # è®¾ç½®APIè¯·æ±‚å¤´
            api_headers = {
                "accept": "*/*",
                "accept-language": "zh-CN,zh;q=0.9",
                "Cookie": cookie_str1,
                "p-pin": "",
                "priority": "u=1, i",
                "referer": "https://ppzh.jd.com/brand/reportCenter/myReport.html",
                "sec-ch-ua": "\"Not=A?Brand\";v=\"24\", \"Chromium\";v=\"140\"",
                "sec-ch-ua-mobile": "?0",
                "sec-ch-ua-platform": "\"Windows\"",
                "sec-fetch-dest": "empty",
                "sec-fetch-mode": "cors",
                "sec-fetch-site": "same-origin",
                "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
                "user-mnp": "dfe8c70a03ddb7554dbb93a150a40a25",
                "user-mup": "1758866860479",
                "x-requested-with": "XMLHttpRequest"
            }
            
            # è®¾ç½®å¾ªç¯å‚æ•°
            max_attempts = 60  # æœ€å¤§å°è¯•æ¬¡æ•°ï¼ˆé¿å…æ— é™å¾ªç¯ï¼‰
            attempt = 0        # å½“å‰å°è¯•æ¬¡æ•°
            download_url = None      # ä¸‹è½½é“¾æ¥
            download_success = False # ä¸‹è½½æ˜¯å¦æˆåŠŸ
            
            # å¼€å§‹å¾ªç¯æ£€æŸ¥æŠ¥è¡¨çŠ¶æ€
            # while å¾ªç¯ï¼šå½“æ¡ä»¶ä¸ºTrueæ—¶ç»§ç»­æ‰§è¡Œ
            while attempt < max_attempts:
                try:
                    print(f"ğŸ” ç¬¬{attempt + 1}æ¬¡æ£€æŸ¥æŠ¥è¡¨çŠ¶æ€...")
                    
                    # å‘é€GETè¯·æ±‚è·å–æŠ¥è¡¨åˆ—è¡¨
                    # requests.get() å‘é€GETè¯·æ±‚
                    api_response = requests.get(api_url, headers=api_headers)
                    
                    # æ£€æŸ¥å“åº”æ˜¯å¦æˆåŠŸ
                    # raise_for_status() å¦‚æœçŠ¶æ€ç ä¸æ˜¯200ä¼šæŠ›å‡ºå¼‚å¸¸
                    api_response.raise_for_status()
                    
                    # è§£æJSONå“åº”
                    # .json() æ–¹æ³•å°†å“åº”å†…å®¹è§£æä¸ºPythonå­—å…¸
                    response_data = api_response.json()
                    
                    # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«æ•°æ®
                    # .get() æ–¹æ³•å®‰å…¨åœ°è·å–å­—å…¸ä¸­çš„å€¼ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›é»˜è®¤å€¼
                    if response_data.get('message') == 'success' and response_data.get('content', {}).get('data'):
                        reports = response_data['content']['data']
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰æŠ¥è¡¨æ•°æ®
                        if reports:
                            # è·å–ç¬¬ä¸€ä¸ªæŠ¥è¡¨çš„ä¿¡æ¯
                            first_report = reports[0]
                            status = first_report.get('status')
                            report_name = first_report.get('reportName', 'æœªçŸ¥æŠ¥è¡¨')
                            
                            print(f"ğŸ“Š æŠ¥è¡¨åç§°ï¼š{report_name}")
                            print(f"ğŸ“Š æŠ¥è¡¨çŠ¶æ€ï¼š{status}")
                            
                            # æ£€æŸ¥æŠ¥è¡¨æ˜¯å¦å®Œæˆ
                            if status == "2":  # çŠ¶æ€2è¡¨ç¤ºå·²å®Œæˆ
                                # è·å–ä¸‹è½½é“¾æ¥
                                download_url = first_report.get('downloadLink', '').strip()
                                
                                if download_url:
                                    print(f"âœ… æŠ¥è¡¨ç”Ÿæˆå®Œæˆï¼å¼€å§‹ä¸‹è½½...")
                                    
                                    # ========================================
                                    # æ­¥éª¤6ï¼šä¸‹è½½æ–‡ä»¶
                                    # ========================================
                                    
                                    # åˆ›å»ºæ—¥æœŸç›®å½•
                                    # Path() åˆ›å»ºè·¯å¾„å¯¹è±¡
                                    # mkdir() åˆ›å»ºç›®å½•
                                    # parents=True åˆ›å»ºçˆ¶ç›®å½•
                                    # exist_ok=True å¦‚æœå·²å­˜åœ¨ä¸æŠ¥é”™
                                    date_dir = BASE_ARCHIVE_DIR / TODAY_STR
                                    date_dir.mkdir(parents=True, exist_ok=True)
                                    # ğŸ“š çŸ¥è¯†ç‚¹ï¼šPathå¯¹è±¡çš„æ–¹æ³•
                                    # .mkdir(): åˆ›å»ºç›®å½•
                                    # .exists(): æ£€æŸ¥æ˜¯å¦å­˜åœ¨
                                    # .unlink(): åˆ é™¤æ–‡ä»¶
                                    # .glob(): æ¨¡å¼åŒ¹é…æŸ¥æ‰¾æ–‡ä»¶
                                    # .parent: è·å–çˆ¶ç›®å½•
                                    # .name: è·å–æ–‡ä»¶å
                                    # .suffix: è·å–æ–‡ä»¶æ‰©å±•å
                                    
                                    # ç”Ÿæˆæ–‡ä»¶å
                                    filename = f"{shop_name}.xlsx"
                                    file_path = date_dir / filename
                                    
                                    print(f"ğŸ’¾ ä¿å­˜è·¯å¾„ï¼š{file_path}")
                                    
                                    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                                    if file_path.exists():
                                        print(f"ğŸ—‘ï¸ å‘ç°åŒåæ–‡ä»¶ï¼Œæ­£åœ¨åˆ é™¤...")
                                        file_path.unlink()  # unlink() åˆ é™¤æ–‡ä»¶
                                        print(f"âœ… åŒåæ–‡ä»¶å·²åˆ é™¤")
                                    
                                    # ä¸‹è½½æ–‡ä»¶
                                    print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½æ–‡ä»¶...")
                                    
                                    # stream=True è¡¨ç¤ºæµå¼ä¸‹è½½ï¼ˆé€‚åˆå¤§æ–‡ä»¶ï¼‰
                                    download_response = requests.get(download_url, stream=True)
                                    download_response.raise_for_status()
                                    # ğŸ“š çŸ¥è¯†ç‚¹ï¼šæ–‡ä»¶ä¸‹è½½çš„æœ€ä½³å®è·µ
                                    # stream=True: æµå¼ä¸‹è½½ï¼Œä¸ä¼šä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
                                    # é€‚åˆå¤§æ–‡ä»¶ä¸‹è½½
                                    # å¯ä»¥æ˜¾ç¤ºä¸‹è½½è¿›åº¦
                                    
                                    # å†™å…¥æ–‡ä»¶
                                    # 'wb' è¡¨ç¤ºä»¥äºŒè¿›åˆ¶å†™å…¥æ¨¡å¼æ‰“å¼€æ–‡ä»¶
                                    with open(file_path, 'wb') as f:
                                        # iter_content() åˆ†å—è¯»å–å†…å®¹
                                        # chunk_size=8192 æ¯æ¬¡è¯»å–8KB
                                        for chunk in download_response.iter_content(chunk_size=8192):
                                            f.write(chunk)
                                    # ğŸ“š çŸ¥è¯†ç‚¹ï¼šæ–‡ä»¶æ“ä½œæ¨¡å¼
                                    # 'r': è¯»å–æ–‡æœ¬æ–‡ä»¶
                                    # 'w': å†™å…¥æ–‡æœ¬æ–‡ä»¶
                                    # 'rb': è¯»å–äºŒè¿›åˆ¶æ–‡ä»¶
                                    # 'wb': å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶
                                    # 'a': è¿½åŠ æ¨¡å¼
                                    
                                    print(f"âœ… æ–‡ä»¶ä¸‹è½½å®Œæˆï¼š{file_path}")
                                    download_success = True
                                    break  # è·³å‡ºwhileå¾ªç¯
                                else:
                                    print(f"âŒ æŠ¥è¡¨å·²å®Œæˆä½†æœªè·å–åˆ°ä¸‹è½½é“¾æ¥")
                                    break
                            else:
                                print(f"â³ æŠ¥è¡¨çŠ¶æ€ä¸º {status}ï¼Œç»§ç»­ç­‰å¾…...")
                        else:
                            print(f"â³ æš‚æ— æŠ¥è¡¨æ•°æ®ï¼Œç»§ç»­ç­‰å¾…...")
                    else:
                        print(f"â³ APIå“åº”å¼‚å¸¸ï¼Œç»§ç»­ç­‰å¾…...")
                
                except requests.exceptions.RequestException as e:
                    print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸ï¼š{e}")
                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æå¼‚å¸¸ï¼š{e}")
                except Exception as e:
                    print(f"âŒ å…¶ä»–å¼‚å¸¸ï¼š{e}")
                # ğŸ“š çŸ¥è¯†ç‚¹ï¼šå¼‚å¸¸å¤„ç†çš„å±‚æ¬¡ç»“æ„
                # Exception (åŸºç±»)
                # â”œâ”€â”€ requests.exceptions.RequestException (ç½‘ç»œå¼‚å¸¸)
                # â”‚   â”œâ”€â”€ ConnectionError (è¿æ¥é”™è¯¯)
                # â”‚   â”œâ”€â”€ Timeout (è¶…æ—¶)
                # â”‚   â””â”€â”€ HTTPError (HTTPé”™è¯¯)
                # â”œâ”€â”€ json.JSONDecodeError (JSONè§£æé”™è¯¯)
                # â””â”€â”€ å…¶ä»–å¼‚å¸¸
                
                # å¢åŠ å°è¯•æ¬¡æ•°
                attempt += 1
                
                # å¦‚æœè¿˜æ²¡æœ‰æˆåŠŸï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†è¯•
                if attempt < max_attempts and not download_success:
                    print(f"â° ç­‰å¾…10ç§’åè¿›è¡Œç¬¬{attempt + 1}æ¬¡å°è¯•...")
                    time.sleep(10)  # ç­‰å¾…10ç§’
                    # ğŸ“š çŸ¥è¯†ç‚¹ï¼šè½®è¯¢é—´éš”çš„é€‰æ‹©
                    # å¤ªçŸ­ï¼šæµªè´¹èµ„æºï¼Œå¯èƒ½è¢«æœåŠ¡å™¨é™åˆ¶
                    # å¤ªé•¿ï¼šç”¨æˆ·ä½“éªŒå·®
                    # ä¸€èˆ¬é€‰æ‹©5-30ç§’ä¹‹é—´
            
            # æ£€æŸ¥æœ€ç»ˆç»“æœ
            if download_success:
                print(f"ğŸ‰ åº—é“º {shop_name} æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True
            else:
                print(f"âŒ åº—é“º {shop_name} æ•°æ®ä¸‹è½½å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°")
                return False
    
    except Exception as e:
        print(f"âŒ å¤„ç†åº—é“º {shop_name} æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{e}")
        return False


def upload_merged_file_to_minio(merged_file_path: str, date_str: str = None) -> bool:
    """
    å°†åˆå¹¶åçš„Excelæ–‡ä»¶ä¸Šä¼ åˆ°MinIOæ•°æ®ä»“åº“
    
    å‡½æ•°è¯´æ˜ï¼š
    - è¯»å–åˆå¹¶åçš„Excelæ–‡ä»¶
    - è½¬æ¢æ•°æ®æ ¼å¼
    - ä¸Šä¼ åˆ°MinIOæ•°æ®ä»“åº“
    
    å‚æ•°è¯´æ˜ï¼š
    - merged_file_path: åˆå¹¶åçš„Excelæ–‡ä»¶è·¯å¾„ï¼ˆå­—ç¬¦ä¸²ï¼‰
    - date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œé»˜è®¤ä½¿ç”¨ä»Šå¤©ï¼ˆå¯é€‰å‚æ•°ï¼‰
    
    è¿”å›å€¼ï¼š
    - True: ä¸Šä¼ æˆåŠŸ
    - False: ä¸Šä¼ å¤±è´¥
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    success = upload_merged_file_to_minio("åˆå¹¶æ–‡ä»¶.xlsx", "2025-09-26")
    if success:
        print("ä¸Šä¼ æˆåŠŸ")
    """
    
    # å¦‚æœæ²¡æœ‰æä¾›æ—¥æœŸï¼Œä½¿ç”¨é»˜è®¤æ—¥æœŸ
    if date_str is None:
        date_str = TODAY_STR
    
    print(f"â˜ï¸ å¼€å§‹ä¸Šä¼ æ–‡ä»¶åˆ°MinIOï¼š{merged_file_path}")
    
    try:
        # ========================================
        # æ­¥éª¤1ï¼šè¯»å–Excelæ–‡ä»¶
        # ========================================
        
        print(f"ğŸ“– æ­£åœ¨è¯»å–Excelæ–‡ä»¶...")
        
        # pd.read_excel() è¯»å–Excelæ–‡ä»¶ä¸ºDataFrame
        df = pd.read_excel(merged_file_path)
        
        print(f"ğŸ“Š æ–‡ä»¶åŒ…å« {len(df)} è¡Œæ•°æ®ï¼Œ{len(df.columns)} åˆ—")
        
        # ========================================
        # æ­¥éª¤2ï¼šæ„å»ºMinIOè·¯å¾„
        # ========================================
        
        # æ„å»ºMinIOä¸­çš„å­˜å‚¨è·¯å¾„
        # è·¯å¾„æ ¼å¼ï¼šods/jd/jd_store/dt=æ—¥æœŸ/æ–‡ä»¶å.parquet
        minio_path = f"ods/jd/jd_store/dt={date_str}/merged_store_data.parquet"
        
        print(f"ğŸ—‚ï¸ MinIOå­˜å‚¨è·¯å¾„ï¼š{minio_path}")
        
        # ========================================
        # æ­¥éª¤3ï¼šæ•°æ®æ¸…ç†
        # ========================================
        
        print(f"ğŸ§¹ æ­£åœ¨æ¸…ç†æ•°æ®...")
        
        # å¤„ç†NaNå€¼ï¼ˆç©ºå€¼ï¼‰
        # fillna('') å°†æ‰€æœ‰NaNå€¼æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
        df = df.fillna('')
        
        # å¤„ç†æ— ç©·å¤§å€¼
        # replace() æ›¿æ¢æŒ‡å®šå€¼
        # float('inf') æ­£æ— ç©·å¤§
        # float('-inf') è´Ÿæ— ç©·å¤§
        df = df.replace([float('inf'), float('-inf')], '')
        
        # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½èƒ½æ­£å¸¸åºåˆ—åŒ–
        for col in df.columns:
            # æ£€æŸ¥åˆ—çš„æ•°æ®ç±»å‹
            if df[col].dtype in ['float64', 'float32']:
                # å¤„ç†æµ®ç‚¹æ•°åˆ—çš„æ— ç©·å¤§å€¼
                df[col] = df[col].replace([float('inf'), float('-inf')], '')
            
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼ˆé¿å…åºåˆ—åŒ–é—®é¢˜ï¼‰
            # astype(str) è½¬æ¢æ•°æ®ç±»å‹
            df[col] = df[col].astype(str)
        
        print(f"âœ… æ•°æ®æ¸…ç†å®Œæˆ")
        
        # ========================================
        # æ­¥éª¤4ï¼šå‡†å¤‡ä¸Šä¼ æ•°æ®
        # ========================================
        
        print(f"ğŸ“¦ æ­£åœ¨å‡†å¤‡ä¸Šä¼ æ•°æ®...")
        
        # å‡†å¤‡ä¸Šä¼ çš„æ•°æ®ç»“æ„
        upload_data = {
            "data": df.to_dict('records'),  # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨æ ¼å¼
            "target_path": minio_path,      # ç›®æ ‡è·¯å¾„
            "format": "parquet",            # æ–‡ä»¶æ ¼å¼
            "bucket": MINIO_BUCKET          # å­˜å‚¨æ¡¶
        }
        
        print(f"ğŸ“Š æ•°æ®è®°å½•æ•°ï¼š{len(upload_data['data'])}")
        
        # ========================================
        # æ­¥éª¤5ï¼šå‘é€ä¸Šä¼ è¯·æ±‚
        # ========================================
        
        print(f"ğŸš€ æ­£åœ¨å‘é€ä¸Šä¼ è¯·æ±‚...")
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {'Content-Type': 'application/json'}
        
        # å‘é€POSTè¯·æ±‚
        # json=upload_data è‡ªåŠ¨å°†å­—å…¸è½¬æ¢ä¸ºJSONå¹¶è®¾ç½®æ­£ç¡®çš„Content-Type
        response = requests.post(MINIO_API_URL, json=upload_data, headers=headers)
        
        print(f"ğŸ“¡ ä¸Šä¼ å“åº”çŠ¶æ€ç ï¼š{response.status_code}")
        
        # ========================================
        # æ­¥éª¤6ï¼šæ£€æŸ¥ä¸Šä¼ ç»“æœ
        # ========================================
        
        if response.status_code == 200:
            # è§£æå“åº”ç»“æœ
            result = response.json()
            
            if result.get('success'):
                print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸåˆ°MinIOï¼š{minio_path}")
                return True
            else:
                error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                print(f"âŒ MinIOä¸Šä¼ å¤±è´¥ï¼š{error_msg}")
                return False
        else:
            print(f"âŒ MinIO APIè¯·æ±‚å¤±è´¥ï¼š{response.status_code}")
            print(f"âŒ é”™è¯¯è¯¦æƒ…ï¼š{response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ ä¸Šä¼ æ–‡ä»¶åˆ°MinIOæ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        return False


# ========================================
# ç¬¬å››éƒ¨åˆ†ï¼šä¸»ç¨‹åºï¼ˆMain Programï¼‰
# ========================================

if __name__ == '__main__':
    """
    ä¸»ç¨‹åºå…¥å£
    
    è¿™é‡Œæ˜¯ç¨‹åºçš„ä¸»è¦æ‰§è¡Œé€»è¾‘ï¼š
    1. è¯»å–Excelé…ç½®æ–‡ä»¶
    2. æ›´æ–°è¡¨å¤´
    3. æ”¶é›†éœ€è¦ä¸‹è½½çš„åº—é“ºä¿¡æ¯
    4. æ‰¹é‡ä¸‹è½½æ–‡ä»¶
    5. åˆå¹¶æ–‡ä»¶
    6. ä¸Šä¼ åˆ°æ•°æ®ä»“åº“
    7. åˆ·æ–°æ•°æ®é›†
    
    if __name__ == '__main__': çš„ä½œç”¨ï¼š
    - åªæœ‰ç›´æ¥è¿è¡Œè¿™ä¸ªè„šæœ¬æ—¶æ‰ä¼šæ‰§è¡Œä¸‹é¢çš„ä»£ç 
    - å¦‚æœè¿™ä¸ªæ–‡ä»¶è¢«å…¶ä»–è„šæœ¬å¯¼å…¥ï¼Œä¸‹é¢çš„ä»£ç ä¸ä¼šæ‰§è¡Œ
    """
    
    print("=" * 60)
    print("ğŸš€ äº¬ä¸œåº—é“ºåº“å­˜æ•°æ®è‡ªåŠ¨æ‹‰å–ç¨‹åºå¯åŠ¨")
    print("=" * 60)
    
    # ========================================
    # æ­¥éª¤1ï¼šè¯»å–å’Œæ›´æ–°Excelé…ç½®æ–‡ä»¶
    # ========================================
    
    print(f"\nğŸ“‹ æ­¥éª¤1ï¼šè¯»å–Excelé…ç½®æ–‡ä»¶")
    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„ï¼š{EXCEL_PATH}")
    
    try:
        # è¯»å–Excelæ–‡ä»¶
        # pd.read_excel() å‚æ•°è¯´æ˜ï¼š
        # - ç¬¬ä¸€ä¸ªå‚æ•°ï¼šæ–‡ä»¶è·¯å¾„
        # - sheet_nameï¼šå·¥ä½œè¡¨åç§°æˆ–ç´¢å¼•
        df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET)
        
        print(f"âœ… Excelæ–‡ä»¶è¯»å–æˆåŠŸ")
        print(f"ğŸ“Š æ•°æ®å½¢çŠ¶ï¼š{df.shape[0]}è¡Œ x {df.shape[1]}åˆ—")
        
    except Exception as e:
        print(f"âŒ è¯»å–Excelæ–‡ä»¶å¤±è´¥ï¼š{e}")
        print("ğŸ›‘ ç¨‹åºç»ˆæ­¢")
        exit(1)  # é€€å‡ºç¨‹åºï¼Œè¿”å›é”™è¯¯ä»£ç 1
    
    # æ›´æ–°è¡¨å¤´
    print(f"\nğŸ”„ æ­£åœ¨æ£€æŸ¥å’Œæ›´æ–°è¡¨å¤´...")
    header_updated = update_header_once(df)
    
    # å¦‚æœè¡¨å¤´æ›´æ–°äº†ï¼Œéœ€è¦é‡æ–°è¯»å–DataFrame
    if header_updated:
        print(f"ğŸ”„ é‡æ–°è¯»å–æ›´æ–°åçš„Excelæ–‡ä»¶...")
        df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET)
    
    # ========================================
    # æ­¥éª¤2ï¼šåˆ†æExcelæ•°æ®ç»“æ„
    # ========================================
    
    print(f"\nğŸ“‹ æ­¥éª¤2ï¼šåˆ†ææ•°æ®ç»“æ„")
    
    # å®šä¹‰é‡è¦åˆ—çš„ç´¢å¼•ï¼ˆä»0å¼€å§‹è®¡æ•°ï¼‰
    shop_idx = 1      # Båˆ—ï¼šåº—é“ºåç§°
    profile_idx = 4   # Eåˆ—ï¼šæµè§ˆå™¨é…ç½®
    status_idx = 5    # Fåˆ—ï¼šä¸‹è½½çŠ¶æ€
    
    print(f"ğŸ“Š æ•°æ®ç»“æ„åˆ†æï¼š")
    print(f"   - æ€»è¡Œæ•°ï¼š{len(df)}")
    print(f"   - æ€»åˆ—æ•°ï¼š{len(df.columns)}")
    print(f"   - åˆ—åï¼š{list(df.columns)}")
    print(f"   - åº—é“ºåç§°åˆ—ï¼ˆBåˆ—ï¼‰ï¼š{df.columns[shop_idx]}")
    print(f"   - æµè§ˆå™¨é…ç½®åˆ—ï¼ˆEåˆ—ï¼‰ï¼š{df.columns[profile_idx]}")
    print(f"   - çŠ¶æ€åˆ—ï¼ˆFåˆ—ï¼‰ï¼š{df.columns[status_idx]}")
    
    # ========================================
    # æ­¥éª¤3ï¼šæ”¶é›†éœ€è¦ä¸‹è½½çš„åº—é“ºä¿¡æ¯
    # ========================================
    
    print(f"\nğŸ“‹ æ­¥éª¤3ï¼šæ”¶é›†éœ€è¦ä¸‹è½½çš„åº—é“º")
    
    # åˆ›å»ºä¸‹è½½ä»»åŠ¡åˆ—è¡¨
    download_tasks = []
    
    # éå†æ¯ä¸€è¡Œæ•°æ®
    # range(len(df)) ç”Ÿæˆä»0åˆ°æ•°æ®è¡Œæ•°-1çš„åºåˆ—
    for row_idx in range(len(df)):
        
        # è·å–å½“å‰è¡Œçš„æ•°æ®
        # df.iloc[è¡Œç´¢å¼•, åˆ—ç´¢å¼•] è·å–æŒ‡å®šä½ç½®çš„æ•°æ®
        shop = df.iloc[row_idx, shop_idx]        # åº—é“ºåç§°
        profile = df.iloc[row_idx, profile_idx]  # æµè§ˆå™¨é…ç½®
        status = df.iloc[row_idx, status_idx]    # ä¸‹è½½çŠ¶æ€
        
        # å¤„ç†çŠ¶æ€å€¼
        # pd.notna() æ£€æŸ¥å€¼æ˜¯å¦ä¸ä¸ºç©º
        # str() è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        status_str = str(status) if pd.notna(status) else ''
        
        print(f"ğŸ” æ£€æŸ¥ç¬¬{row_idx + 2}è¡Œï¼šåº—é“º={shop}, é…ç½®={profile}, çŠ¶æ€='{status_str}'")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡
        
        # 1. æ£€æŸ¥çŠ¶æ€æ˜¯å¦å·²å®Œæˆ
        if status_str.strip() == 'å·²å®Œæˆ':
            print(f"   â© çŠ¶æ€å·²å®Œæˆï¼Œè·³è¿‡")
            continue
        
        # 2. æ£€æŸ¥æµè§ˆå™¨é…ç½®æ˜¯å¦ä¸ºç©º
        # pd.isna() æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå€¼
        if pd.isna(profile) or str(profile).strip() == '' or str(profile).strip() == 'nan':
            print(f"   âš ï¸ æµè§ˆå™¨é…ç½®ä¸ºç©ºï¼Œè·³è¿‡")
            continue
        
        # 3. æ£€æŸ¥åº—é“ºåç§°æ˜¯å¦ä¸ºç©º
        if pd.isna(shop) or str(shop).strip() == '':
            print(f"   âš ï¸ åº—é“ºåç§°ä¸ºç©ºï¼Œè·³è¿‡")
            continue
        
        # æ·»åŠ åˆ°ä¸‹è½½ä»»åŠ¡åˆ—è¡¨
        download_tasks.append({
            'row_idx': row_idx,           # è¡Œç´¢å¼•ï¼ˆç”¨äºåç»­æ›´æ–°çŠ¶æ€ï¼‰
            'shop': str(shop).strip(),    # åº—é“ºåç§°
            'profile': str(profile).strip()  # æµè§ˆå™¨é…ç½®
        })
        
        print(f"   âœ… å·²æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—")
    
    print(f"\nğŸ“Š ä»»åŠ¡ç»Ÿè®¡ï¼š")
    print(f"   - æ€»åº—é“ºæ•°ï¼š{len(df)}")
    print(f"   - éœ€è¦ä¸‹è½½ï¼š{len(download_tasks)}")
    print(f"   - è·³è¿‡æ•°é‡ï¼š{len(df) - len(download_tasks)}")
    
    # å¦‚æœæ²¡æœ‰éœ€è¦ä¸‹è½½çš„ä»»åŠ¡ï¼Œæå‰ç»“æŸ
    if len(download_tasks) == 0:
        print(f"\nâœ… æ²¡æœ‰éœ€è¦ä¸‹è½½çš„åº—é“ºï¼Œç¨‹åºç»“æŸ")
        exit(0)
    
    # ========================================
    # æ­¥éª¤4ï¼šæ‰¹é‡ä¸‹è½½æ–‡ä»¶
    # ========================================
    
    print(f"\nğŸ“‹ æ­¥éª¤4ï¼šå¼€å§‹æ‰¹é‡ä¸‹è½½")
    
    # è®°å½•ä¸‹è½½æˆåŠŸçš„æ–‡ä»¶
    downloaded_files = []
    
    # éå†æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
    # enumerate() å‡½æ•°è¿”å›ç´¢å¼•å’Œå€¼çš„å…ƒç»„
    for task_idx, task in enumerate(download_tasks):
        
        print(f"\nğŸ¯ å¤„ç†ä»»åŠ¡ {task_idx + 1}/{len(download_tasks)}")
        
        row_idx = task['row_idx']
        shop = task['shop']
        profile = task['profile']
        
        print(f"ğŸ“ åº—é“ºï¼š{shop}")
        print(f"ğŸ“ é…ç½®ï¼š{profile}")
        
        try:
            # è°ƒç”¨ä¸‹è½½å‡½æ•°
            success = fetch_download_link_and_download(shop, profile)
            
            if success:
                print(f"âœ… {shop} ä¸‹è½½æˆåŠŸ")
                
                # è®°å½•ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„
                date_dir = BASE_ARCHIVE_DIR / TODAY_STR
                file_path = date_dir / f"{shop}.xlsx"
                downloaded_files.append(file_path)
                
                # æ›´æ–°Excelä¸­çš„çŠ¶æ€ä¸º"å·²å®Œæˆ"
                df.iloc[row_idx, status_idx] = 'å·²å®Œæˆ'
                
            else:
                print(f"âŒ {shop} ä¸‹è½½å¤±è´¥")
                
                # å¤±è´¥æ—¶æ¸…ç©ºçŠ¶æ€ï¼Œä¾¿äºé‡è¯•
                df.iloc[row_idx, status_idx] = ''
                
        except Exception as e:
            print(f"âŒ {shop} å¤„ç†å¼‚å¸¸ï¼š{str(e)}")
            
            # å¼‚å¸¸æ—¶ä¹Ÿæ¸…ç©ºçŠ¶æ€
            df.iloc[row_idx, status_idx] = ''
    
    # ========================================
    # æ­¥éª¤5ï¼šä¿å­˜ExcelçŠ¶æ€æ›´æ–°
    # ========================================
    
    print(f"\nğŸ“‹ æ­¥éª¤5ï¼šä¿å­˜çŠ¶æ€æ›´æ–°")
    
    try:
        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ–‡ä»¶æ²¡æœ‰è¢«å ç”¨
        time.sleep(1)
        
        # ä¿å­˜æ›´æ–°åçš„DataFrameåˆ°Excel
        df.to_excel(EXCEL_PATH, index=False, engine='openpyxl')
        
        print(f"âœ… ExcelçŠ¶æ€å·²æ›´æ–°å¹¶ä¿å­˜")
        
    except PermissionError as e:
        print(f"âš ï¸ Excelæ–‡ä»¶è¢«å ç”¨ï¼Œæ— æ³•ä¿å­˜çŠ¶æ€ï¼š{e}")
        print(f"ğŸ’¡ è¯·å…³é—­Excelæ–‡ä»¶åé‡æ–°è¿è¡Œè„šæœ¬")
    except Exception as e:
        print(f"âŒ ä¿å­˜Excelæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
    
    # ========================================
    # æ­¥éª¤6ï¼šåˆå¹¶ä¸‹è½½çš„æ–‡ä»¶
    # ========================================
    
    print(f"\nğŸ“‹ æ­¥éª¤6ï¼šåˆå¹¶Excelæ–‡ä»¶")
    
    if downloaded_files:
        print(f"ğŸ“Š å‡†å¤‡åˆå¹¶ {len(downloaded_files)} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºè¦åˆå¹¶çš„æ–‡ä»¶åˆ—è¡¨
        for i, file_path in enumerate(downloaded_files, 1):
            print(f"   {i}. {file_path.name}")
        
        try:
            # åˆ›å»ºæ—¥æœŸç›®å½•è·¯å¾„
            date_dir = BASE_ARCHIVE_DIR / TODAY_STR
            
            # ä½¿ç”¨ExcelMergeråˆå¹¶æ–‡ä»¶
            print(f"ğŸ”„ æ­£åœ¨åˆå¹¶æ–‡ä»¶...")
            
            merger = ExcelMerger(str(date_dir))
            merge_filename = f"äº¬ä¸œåº“å­˜åˆå¹¶_{TODAY_STR}.xlsx"
            merge_success = merger.merge_excel_files(merge_filename)
            
            if merge_success:
                # åˆå¹¶æˆåŠŸï¼Œç§»åŠ¨æ–‡ä»¶åˆ°æœ€ç»ˆç›®å½•
                merged_file_path = date_dir / merge_filename
                final_merged_file_path = MERGED_FILES_DIR / merge_filename
                
                # ä½¿ç”¨shutil.move()ç§»åŠ¨æ–‡ä»¶
                shutil.move(str(merged_file_path), str(final_merged_file_path))
                
                print(f"âœ… æ–‡ä»¶åˆå¹¶å®Œæˆï¼š{final_merged_file_path}")
                
                # ========================================
                # æ­¥éª¤7ï¼šä¸Šä¼ åˆ°MinIOæ•°æ®ä»“åº“
                # ========================================
                
                print(f"\nğŸ“‹ æ­¥éª¤7ï¼šä¸Šä¼ åˆ°æ•°æ®ä»“åº“")
                
                print(f"â˜ï¸ æ­£åœ¨ä¸Šä¼ åˆå¹¶æ–‡ä»¶åˆ°MinIO...")
                upload_success = upload_merged_file_to_minio(str(final_merged_file_path), TODAY_STR)
                
                if upload_success:
                    print(f"âœ… MinIOä¸Šä¼ æˆåŠŸ")
                else:
                    print(f"âš ï¸ MinIOä¸Šä¼ å¤±è´¥ï¼Œä½†æœ¬åœ°æ–‡ä»¶å·²ä¿å­˜")
                    
            else:
                print(f"âŒ æ–‡ä»¶åˆå¹¶å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ åˆå¹¶æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
    else:
        print(f"âš ï¸ æ²¡æœ‰æ–°ä¸‹è½½çš„æ–‡ä»¶ï¼Œè·³è¿‡åˆå¹¶æ­¥éª¤")
    
    # ========================================
    # æ­¥éª¤8ï¼šåˆ·æ–°æ•°æ®é›†å’Œåå°„
    # ========================================
    
    print(f"\nğŸ“‹ æ­¥éª¤8ï¼šåˆ·æ–°æ•°æ®ä»“åº“")
    
    # åˆ·æ–°æ•°æ®é›†å…ƒæ•°æ®
    print(f"ğŸ”„ æ­£åœ¨åˆ·æ–°æ•°æ®é›†å…ƒæ•°æ®...")
    
    try:
        refresh_dataset_response = requests.post(
            "http://localhost:8003/api/dataset/refresh-metadata",
            headers={"Content-Type": "application/json"},
            json={"dataset_path": "minio.warehouse.ods.jd.jd_store"}
        )
        
        if refresh_dataset_response.status_code == 200:
            print(f"âœ… æ•°æ®é›†å…ƒæ•°æ®åˆ·æ–°æˆåŠŸ")
        else:
            print(f"âš ï¸ æ•°æ®é›†å…ƒæ•°æ®åˆ·æ–°å¤±è´¥ï¼š{refresh_dataset_response.status_code}")
            
    except Exception as e:
        print(f"âŒ æ•°æ®é›†å…ƒæ•°æ®åˆ·æ–°å¼‚å¸¸ï¼š{e}")
    
    # åˆ·æ–°åå°„
    print(f"ğŸ”„ æ­£åœ¨åˆ·æ–°æ•°æ®åå°„...")
    
    try:
        refresh_reflection_response = requests.post(
            "http://localhost:8003/api/reflection/refresh",
            headers={"Content-Type": "application/json"},
            json={"dataset_path": "minio.warehouse.ods.jd.jd_store"}
        )
        
        if refresh_reflection_response.status_code == 200:
            print(f"âœ… æ•°æ®åå°„åˆ·æ–°æˆåŠŸ")
        else:
            print(f"âš ï¸ æ•°æ®åå°„åˆ·æ–°å¤±è´¥ï¼š{refresh_reflection_response.status_code}")
            
    except Exception as e:
        print(f"âŒ æ•°æ®åå°„åˆ·æ–°å¼‚å¸¸ï¼š{e}")
    
    # ========================================
    # ç¨‹åºç»“æŸ
    # ========================================
    
    print(f"\n" + "=" * 60)
    print(f"ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
    print(f"ğŸ“Š æ‰§è¡Œç»Ÿè®¡ï¼š")
    print(f"   - å¤„ç†æ—¥æœŸï¼š{TODAY_STR}")
    print(f"   - æ€»ä»»åŠ¡æ•°ï¼š{len(download_tasks)}")
    print(f"   - æˆåŠŸä¸‹è½½ï¼š{len(downloaded_files)}")
    print(f"   - å¤±è´¥æ•°é‡ï¼š{len(download_tasks) - len(downloaded_files)}")
    print(f"=" * 60)

"""
========================================
å­¦ä¹ æ€»ç»“å’Œæ‰©å±•å»ºè®®
========================================

é€šè¿‡è¿™ä¸ªè„šæœ¬ï¼Œä½ å¯ä»¥å­¦åˆ°ï¼š

1. PythonåŸºç¡€è¯­æ³•ï¼š
   - å˜é‡å®šä¹‰å’Œä½¿ç”¨
   - å‡½æ•°å®šä¹‰å’Œè°ƒç”¨
   - æ¡ä»¶åˆ¤æ–­ï¼ˆif/elseï¼‰
   - å¾ªç¯ï¼ˆfor/whileï¼‰
   - å¼‚å¸¸å¤„ç†ï¼ˆtry/exceptï¼‰

2. æ•°æ®å¤„ç†ï¼š
   - pandasåº“çš„ä½¿ç”¨
   - Excelæ–‡ä»¶è¯»å†™
   - æ•°æ®æ¸…ç†å’Œè½¬æ¢

3. ç½‘ç»œç¼–ç¨‹ï¼š
   - HTTPè¯·æ±‚ï¼ˆGET/POSTï¼‰
   - Cookieå¤„ç†
   - æ–‡ä»¶ä¸‹è½½

4. æ–‡ä»¶æ“ä½œï¼š
   - æ–‡ä»¶è·¯å¾„å¤„ç†
   - æ–‡ä»¶åˆ›å»ºã€åˆ é™¤ã€ç§»åŠ¨
   - ç›®å½•æ“ä½œ

5. æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼š
   - Playwrightçš„ä½¿ç”¨
   - é¡µé¢å¯¼èˆªå’Œæ“ä½œ
   - å…ƒç´ å®šä½å’Œäº¤äº’

æ‰©å±•ç»ƒä¹ å»ºè®®ï¼š

1. åˆçº§ç»ƒä¹ ï¼š
   - ä¿®æ”¹æ–‡ä»¶ä¿å­˜è·¯å¾„
   - è°ƒæ•´ç­‰å¾…æ—¶é—´
   - æ·»åŠ æ›´å¤šçš„æ—¥å¿—è¾“å‡º

2. ä¸­çº§ç»ƒä¹ ï¼š
   - æ·»åŠ é‚®ä»¶é€šçŸ¥åŠŸèƒ½
   - å®ç°å¤šçº¿ç¨‹ä¸‹è½½
   - æ·»åŠ é…ç½®æ–‡ä»¶æ”¯æŒ

3. é«˜çº§ç»ƒä¹ ï¼š
   - å®ç°GUIç•Œé¢
   - æ·»åŠ æ•°æ®åº“æ”¯æŒ
   - å®ç°åˆ†å¸ƒå¼å¤„ç†

å­¦ä¹ èµ„æºæ¨èï¼š
- Pythonå®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.python.org/
- pandasæ–‡æ¡£ï¼šhttps://pandas.pydata.org/docs/
- requestsæ–‡æ¡£ï¼šhttps://docs.python-requests.org/
- Playwrightæ–‡æ¡£ï¼šhttps://playwright.dev/python/

è®°ä½ï¼šç¼–ç¨‹æ˜¯ä¸€ä¸ªå®è·µçš„è¿‡ç¨‹ï¼Œå¤šå†™å¤šç»ƒæ‰èƒ½æŒæ¡ï¼
"""